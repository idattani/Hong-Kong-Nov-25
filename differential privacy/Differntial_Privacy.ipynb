{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc20a31",
   "metadata": {},
   "source": [
    "# Differential Privacy Demo\n",
    "\n",
    "**This notebook will:**\n",
    "\n",
    "* Upload a dataset (CSV)\n",
    "* Automatically detect categorical and numerical columns\n",
    "* Train a privacy-preserving synthesizer (patectgan / dpctgan)\n",
    "* Generate synthetic data while preserving structure\n",
    "* Match the schema (int/float precision, categorical types) of the original dataset\n",
    "* Compare the Datasets\n",
    "* Save & download the synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f5c21",
   "metadata": {},
   "source": [
    "### Step 1: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a3d0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy smartnoise-synth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5d205",
   "metadata": {},
   "source": [
    "This installs Pandas, NumPy, and SmartNoise Synth (Microsoftâ€™s DP synthetic data library)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52041ee9",
   "metadata": {},
   "source": [
    "### Step 2: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc9933",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snsynth import Synthesizer\n",
    "from google.colab import files\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a139d45",
   "metadata": {},
   "source": [
    "**We load the libraries:**\n",
    "\n",
    "* pandas â†’ data handling\n",
    "* snsynth â†’ SmartNoise synthesizers\n",
    "* colab.files â†’ file upload/download\n",
    "* ipywidgets â†’ to make interactive controls (slider for epsilon, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3c4de",
   "metadata": {},
   "source": [
    "### Step 3: Upload your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d6f61",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Prompt user to upload CSV\n",
    "print(\"ðŸ“‚ Please upload your CSV dataset:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get uploaded filename\n",
    "INPUT_CSV = list(uploaded.keys())[0]\n",
    "print(f\"âœ… Uploaded file: {INPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53742ae",
   "metadata": {},
   "source": [
    "This cell lets you upload any CSV file. The file is stored in Colab for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d781e35",
   "metadata": {},
   "source": [
    "### Step 4: Configure privacy budget (epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db33632",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive slider for epsilon\n",
    "epsilon_slider = widgets.FloatSlider(\n",
    "    value=1.0,\n",
    "    min=0.1,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Epsilon:',\n",
    "    continuous_update=False\n",
    ")\n",
    "display(epsilon_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beedad1",
   "metadata": {},
   "source": [
    "**Here you can control epsilon (privacy budget).**\n",
    "\n",
    "* Smaller epsilon = stronger privacy, lower accuracy\n",
    "* Larger epsilon = weaker privacy, higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4c1bd",
   "metadata": {},
   "source": [
    "### Step 5: Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f9e73",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def infer_column_types(df, cat_threshold=15):\n",
    "    categorical, continuous, ordinal = [], [], []\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].nunique(dropna=True)\n",
    "        if pd.api.types.is_object_dtype(df[col]) or unique_vals <= cat_threshold:\n",
    "            categorical.append(col)\n",
    "        else:\n",
    "            continuous.append(col)\n",
    "    return categorical, continuous, ordinal\n",
    "\n",
    "def preprocess_dataframe(df, continuous_cols):\n",
    "    for col in continuous_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    return df\n",
    "\n",
    "def count_decimals(series: pd.Series) -> int:\n",
    "    \"\"\"Infer the maximum number of decimal places in a numeric column.\"\"\"\n",
    "    decimals = []\n",
    "    for val in series.dropna().astype(str):\n",
    "        if \".\" in val:\n",
    "            decimals.append(len(val.split(\".\")[1]))\n",
    "    return max(decimals) if decimals else 0\n",
    "\n",
    "def enforce_schema(df_synth, df_original):\n",
    "    \"\"\"Ensure synthetic dataset matches schema and decimal places exactly.\"\"\"\n",
    "    df_fixed = df_synth.copy()\n",
    "    for col in df_original.columns:\n",
    "        if pd.api.types.is_integer_dtype(df_original[col]):\n",
    "            df_fixed[col] = df_fixed[col].round().astype(int)\n",
    "        elif pd.api.types.is_float_dtype(df_original[col]):\n",
    "            dp = count_decimals(df_original[col].astype(str))\n",
    "            df_fixed[col] = df_fixed[col].round(dp).astype(float)\n",
    "            df_fixed[col] = df_fixed[col].map(lambda x: f\"{x:.{dp}f}\")\n",
    "        elif pd.api.types.is_object_dtype(df_original[col]):\n",
    "            df_fixed[col] = df_fixed[col].astype(str)\n",
    "    return df_fixed[df_original.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec628b0",
   "metadata": {},
   "source": [
    "**These functions:**\n",
    "\n",
    "* Detect column types (categorical vs continuous)\n",
    "* Fill missing values\n",
    "* Preserve decimal places + dtypes in synthetic output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086253f",
   "metadata": {},
   "source": [
    "### Step 6: Train synthesizer & generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba674133",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "EPSILON = epsilon_slider.value\n",
    "SYNTH_NAME = \"patectgan\"  # or \"dpctgan\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "print(f\"Loaded {df.shape[0]} rows, {df.shape[1]} columns from {INPUT_CSV}\")\n",
    "\n",
    "# Detect schema\n",
    "categorical_cols, continuous_cols, ordinal_cols = infer_column_types(df)\n",
    "print(\"ðŸ”Ž Detected categorical columns:\", categorical_cols)\n",
    "print(\"ðŸ”Ž Detected continuous columns:\", continuous_cols)\n",
    "\n",
    "# Preprocess\n",
    "df = preprocess_dataframe(df, continuous_cols)\n",
    "\n",
    "# Create and train synthesizer\n",
    "synth = Synthesizer.create(SYNTH_NAME, epsilon=EPSILON, verbose=True)\n",
    "synth.fit(\n",
    "    df,\n",
    "    categorical_columns=categorical_cols,\n",
    "    continuous_columns=continuous_cols,\n",
    "    ordinal_columns=ordinal_cols,\n",
    "    preprocessor_eps=0.2\n",
    ")\n",
    "\n",
    "# Generate synthetic dataset\n",
    "synth_df = synth.sample(df.shape[0])\n",
    "\n",
    "# Enforce schema\n",
    "synth_df = enforce_schema(synth_df, df)\n",
    "\n",
    "print(\"âœ… Synthetic data generated!\")\n",
    "synth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723815ca",
   "metadata": {},
   "source": [
    "This trains the synthesizer and outputs the first 5 rows of synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a025a8",
   "metadata": {},
   "source": [
    "### Step 7: Save & download synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161b781",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_CSV = \"synthetic_dataset.csv\"\n",
    "synth_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"âœ… Synthetic dataset saved to {OUTPUT_CSV}\")\n",
    "\n",
    "files.download(OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5f450",
   "metadata": {},
   "source": [
    "This saves your synthetic dataset and gives you a download link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20970085",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate synthetic dataset quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f93c82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_distributions(df_real, df_synth, max_cols=6):\n",
    "    \"\"\"Plot distributions of real vs synthetic data for both numerical and categorical columns.\"\"\"\n",
    "    cols = df_real.columns[:max_cols]  # limit to first N columns for readability\n",
    "    n = len(cols)\n",
    "    fig, axes = plt.subplots(n, 2, figsize=(12, 4 * n))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]  # ensure iterable\n",
    "\n",
    "    for i, col in enumerate(cols):\n",
    "        ax1, ax2 = axes[i]\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(df_real[col]):\n",
    "            ax1.hist(df_real[col].dropna(), bins=30, alpha=0.7, label=\"Real\", color=\"blue\")\n",
    "            ax2.hist(df_synth[col].dropna().astype(float), bins=30, alpha=0.7, label=\"Synthetic\", color=\"orange\")\n",
    "        else:\n",
    "            df_real[col].value_counts().plot(kind=\"bar\", ax=ax1, color=\"blue\", alpha=0.7)\n",
    "            df_synth[col].value_counts().plot(kind=\"bar\", ax=ax2, color=\"orange\", alpha=0.7)\n",
    "\n",
    "        ax1.set_title(f\"Real: {col}\")\n",
    "        ax2.set_title(f\"Synthetic: {col}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run evaluation\n",
    "compare_distributions(df, synth_df, max_cols=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6cb16",
   "metadata": {},
   "source": [
    "**This will:**\n",
    "\n",
    "* Plot up to 6 columns.\n",
    "* Use histograms for numeric columns.\n",
    "* Use bar charts for categorical columns.\n",
    "* Display side-by-side comparison (real vs synthetic)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
