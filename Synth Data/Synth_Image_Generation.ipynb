{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Image Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a very basic Demo of Synthetic Image Data generation. Run each code block in sequence to generate images. This will generate 3 images based upon the prompt below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to select the T4 GPU in the change runtime menu. Click the arrown next to RAM and DISK. Select CHANGE RUNTIME TYPE and select the T4 GPU. Then run the code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade diffusers transformers accelerate mediapy peft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the model and other requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapy as media\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from diffusers import DiffusionPipeline, TCDScheduler\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Choose either 8 or 12 steps:\n",
    "num_inference_steps = 12\n",
    "\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "repo_name = \"ByteDance/Hyper-SD\"\n",
    "plural = \"s\" if num_inference_steps > 1 else \"\"\n",
    "ckpt_name = f\"Hyper-SDXL-{num_inference_steps}step{plural}-CFG-lora.safetensors\"\n",
    "device = \"cuda\"\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16, variant=\"fp16\").to(device)\n",
    "pipe.load_lora_weights(hf_hub_download(repo_name, ckpt_name))\n",
    "pipe.fuse_lora()\n",
    "pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can change the prompt for the image you want to generate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \" a photo of a Road Sweeper Used to clean the roads and construction areas.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code block to see you images generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "num_images = 3 # Set the number of images to generate\n",
    "num_inference_steps = 40  # Ensure this variable is defined\n",
    "guidance_scale = 9.0\n",
    "eta = 0.5\n",
    "path= 'images/'\n",
    "generator = torch.Generator(device)\n",
    "seed = random.randint(0, sys.maxsize)\n",
    "generator.manual_seed(seed)\n",
    "\n",
    "images = []\n",
    "for i in range(num_images):\n",
    "    generator.manual_seed(seed + i)  # Change seed for variation\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        eta=eta,\n",
    "        generator=generator,\n",
    "    ).images[0]\n",
    "    images.append(image)\n",
    "    image.save(f\"output_{i}.png\")\n",
    "\n",
    "\n",
    "print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n",
    "media.show_images(images)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
